package com.idugalic;

import com.idugalic.commandside.blog.command.CreateBlogPostCommand;
import com.idugalic.common.blog.model.BlogPostCategory;
import com.idugalic.common.model.AuditEntry;
import org.axonframework.commandhandling.gateway.CommandGateway;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.ApplicationArguments;
import org.springframework.boot.ApplicationRunner;
import org.springframework.context.annotation.Profile;
import org.springframework.stereotype.Component;

import java.util.Calendar;

/**
 * @author: idugalic
 * Date: 1/12/18
 * Time: 6:31 PM
 */
@Profile("!cloud")
@Component
public class InitDataLoader implements ApplicationRunner {

    private CommandGateway commandGateway;
    private static final String CURRENT_USER = "admin.admin";

    @Autowired
    public InitDataLoader(CommandGateway commandGateway) {
        this.commandGateway = commandGateway;
    }


    @Override
    public void run(ApplicationArguments args) throws Exception {


        AuditEntry auditEntry = new AuditEntry(CURRENT_USER);
        Calendar future = Calendar.getInstance();
        future.add(Calendar.DAY_OF_YEAR, 1);

        CreateBlogPostCommand command = new CreateBlogPostCommand(
                auditEntry,
                "Accelerating the digitization",
                "For some executives, it\u2019s about technology. For others, digital is a new way of engaging with customers.\n\nIt\u2019s tempting to look for simple definitions, but to be meaningful and sustainable, I believe that digital should be seen less as a thing and more a way of doing things. To help make this definition more concrete, I have broken it down into three attributes: \n- creating value at the new frontiers of the business world, \n- creating value in the processes that execute a vision of customer experiences, \n- and building foundational capabilities that support the entire structure.\n\n\n## The trio - architecture, culture & process\n\nThe main focus of this blog post is the third part of the definition - \"building foundational capabilities that support the entire structure\". This foundation is made up of three elements:\n\n- [Microservices](http://microservices.io/patterns/microservices.html) is the architecture,\n- [DevOps](http://martinfowler.com/bliki/DevOpsCulture.html)\u2014specifically CALMS (collaboration, automation, learning, measuring, and sharing)\u2014is the culture,\n- and [continuous delivery](http://martinfowler.com/bliki/ContinuousDelivery.html) is the process.\n\n### Architecture - Microservices\n\nThe microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API (RESTful). These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.\n\nWhen organizations make the choice to put a digital platform in place, a discussion on Microservices is never far behind. By putting a Microservices layer in place, an organization creates the springboard to launch into the digital future, whether that involves apps, rich Web clients, or IoT devices such as in-store beacons. Individual Microservices, or orchestrated groups of Microservices, serve as the foundation for this innovation. The data being passed to and from Microservices also serves as the basis for behavioral analytics and Big Data, allowing organizations to tailor their digital services based on their users.\n\nA Microservices architecture style brings a lot of operations overhead. Where a monolithic application might have been deployed to a small application server cluster, you now have tens of separate services to build, test, deploy and run, potentially in polyglot languages and environments.\n\n#### Cloud \n\nIf you look at the concerns typically expressed about microservices, you will find that they are exactly the challenges that a PaaS (Platform As A Service) is intended to address.\n\nPaaS offerings like [Cloud Foundry](https://www.cloudfoundry.org/) have raised the level of abstraction to a focus on an ecosystem of applications and services. Cloud Foundry is open source and it can be deployed on private or public (IaaS) infrastructure.\n\nLinux container technology, such as [Docker](https://www.docker.com/), can be used to streamline the development, testing and deployment experience. The Docker platform empowers you to build a [CaaS](https://blog.docker.com/2016/02/containers-as-a-service-caas/) (Containers as a service) that fits your business requirements.\n\n#### Cloud native\n\nA cloud-native application is an application that has been designed and implemented to run on a PaaS or CaaS installation, and to embrace horizontal elastic scaling.\n\n### Culture - collaboration, automation, learning, measuring, and sharing\n\nWestrum\u2019s research emphasizes the importance of creating a culture where new ideas are welcomed, people from across the organization collaborate in the pursuit of common goals, where we train people to bring bad news so we can act on it, and where failures and accidents are treated as opportunities to learn how to improve rather than witch-hunts.\n\nThe DevOps movement has always emphasized the primary importance of culture, with a particular focus on effective collaboration between development teams and IT operations teams.\n\nWith the uptake of microservices and containers new challenges are rising: \u201cHow can we manage aspects such as API contracts?\u201d and \u201cHow can we apply changes across several repositories at once?\u201d. Those challenges highlight the need for greater collaboration between, and within, teams and this is a challenge that [Atomist](https://www.atomist.com) is addressing. Atomist is setting out to tackle with a set of tools that integrate seamlessly with the teams\u2019 practices.\nWith the rise of microservices, project creation is more and more important to individuals and organizations, as is maintaining consistency between a potentially large number of services.\n\nIndeed the highest-performing companies don\u2019t wait for bad things to happen in order to learn how to improve, they create (controlled) accidents on a regular basis so as to learn more quickly than the competition.\n\n\n### Process - Continuous Delivery\n\nThe idea of automated deployment is important. Indeed, if you take automating the deployment process to its logical conclusion, you could push every build that passes the necessary automated tests into production. The practice of automatically deploying every successful build directly into production is generally known as Continuous Deployment.\n\nHowever, a pure Continuous Deployment approach is not always appropriate for everyone. For example, many users would not appreciate new versions falling into their laps several times a week, and prefer a more predictable (and transparent) release cycle. Commercial and marketing considerations might also play a role in when a new release should actually be deployed. The notion of Continuous Delivery is a slight variation on the idea of Continuous Deployment that takes into account these considerations.\n\n[Spinnaker](http://www.spinnaker.io/) is an open source, multi-cloud continuous delivery platform for releasing software changes with high velocity and confidence.\n\n[Jenkins 2](https://jenkins.io/2.0/) pipelines are pretty neat to. I don''t think Spinnaker will every fully replace Jenkins and the million things it does. Spinnaker goal is to just make the ''deploy to cloud'' step simpler and more extensible.\n\n[CircleCI''s](https://circleci.com) continuous integration and delivery platform helps software teams rapidly release code with confidence by automating the build, test, and deploy process. CircleCI offers a modern software development platform that lets teams ramp quickly, scale easily, and build confidently every day. CircleCI offers a total of four free linux containers ($2400 annual value) for open-source projects.\n\n[Travis CI](https://travis-ci.org/) - Test and Deploy with Confidence. Testing your open source project is 10000% free with Travis CI.\n\n### The lab\n\nI have constucted a [lab](http://ivans-innovation-lab.github.io/). It is hosted on [Github](https://github.com/ivans-innovation-lab).\n\nThe intention of this lab is to build information system of fictitious company.\n\nYou will learn how we:\n\n- made decisions to use one pattern against the other,\n- changed architecture, organization (culture) and process over time to respond to new requirements,\n- made a foundation for successful digitalization.\n\nThe ultimate goal is to deliver better software faster. Feel free to join. Let''s learn together!\n'), STRINGDECODE('For some executives, it\u2019s about technology. For others, digital is a new way of engaging with customers.\n\nIt\u2019s tempting to look for simple definitions, but to be meaningful and sustainable, I believe that digital should be seen less as a thing and more a way of doing things. To help make this definition more concrete, I have broken it down into three attributes: \n- creating value at the new frontiers of the business world, \n- creating value in the processes that execute a vision of customer experiences, \n- and building foundational capabilities that support the entire structure.\n\n\n## The trio - architecture, culture & process\n\nThe main focus of this blog post is the third part of the definition - \"building foundational capabilities that support the entire structure\". This foundation is made up of three elements:\n\n- [Microservices](http://microservices.io/patterns/microservices.html) is the architecture,\n- [DevOps](http://martinfowler.com/bliki/DevOpsCulture.html)\u2014specifically CALMS (collaboration, automation, learning, measuring, and sharing)\u2014is the culture,\n- and [continuous delivery](http://martinfowler.com/bliki/ContinuousDelivery.html) is the process.\n\n### Architecture - Microservices\n\nThe microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API (RESTful). These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.\n\nWhen organizations make the choice to put a digital platform in place, a discussion on Microservices is never far behind. By putting a Microservices layer in place, an organization creates the springboard to launch into the digital future, whether that involves apps, rich Web clients, or IoT devices such as in-store beacons. Individual Microservices, or orchestrated groups of Microservices, serve as the foundation for this innovation. The data being passed to and from Microservices also serves as the basis for behavioral analytics and Big Data, allowing organizations to tailor their digital services based on their users.\n\nA Microservices architecture style brings a lot of operations overhead. Where a monolithic application might have been deployed to a small application server cluster, you now have tens of separate services to build, test, deploy and run, potentially in polyglot languages and environments.\n\n#### Cloud \n\nIf you look at the concerns typically expressed about microservices, you will find that they are exactly the challenges that a PaaS (Platform As A Service) is intended to address.\n\nPaaS offerings like [Cloud Foundry](https://www.cloudfoundry.org/) have raised the level of abstraction to a focus on an ecosystem of applications and services. Cloud Foundry is open source and it can be deployed on private or public (IaaS) infrastructure.\n\nLinux container technology, such as [Docker](https://www.docker.com/), can be used to streamline the development, testing and deployment experience. The Docker platform empowers you to build a [CaaS](https://blog.docker.com/2016/02/containers-as-a-service-caas/) (Containers as a service) that fits your business requirements.\n\n#### Cloud native\n\nA cloud-native application is an application that has been designed and implemented to run on a PaaS or CaaS installation, and to embrace horizontal elastic scaling.\n\n### Culture - collaboration, automation, learning, measuring, and sharing\n\nWestrum\u2019s research emphasizes the importance of creating a culture where new ideas are welcomed, people from across the organization collaborate in the pursuit of common goals, where we train people to bring bad news so we can act on it, and where failures and accidents are treated as opportunities to learn how to improve rather than witch-hunts.\n\nThe DevOps movement has always emphasized the primary importance of culture, with a particular focus on effective collaboration between development teams and IT operations teams.\n\nWith the uptake of microservices and containers new challenges are rising: \u201cHow can we manage aspects such as API contracts?\u201d and \u201cHow can we apply changes across several repositories at once?\u201d. Those challenges highlight the need for greater collaboration between, and within, teams and this is a challenge that [Atomist](https://www.atomist.com) is addressing. Atomist is setting out to tackle with a set of tools that integrate seamlessly with the teams\u2019 practices.\nWith the rise of microservices, project creation is more and more important to individuals and organizations, as is maintaining consistency between a potentially large number of services.\n\nIndeed the highest-performing companies don\u2019t wait for bad things to happen in order to learn how to improve, they create (controlled) accidents on a regular basis so as to learn more quickly than the competition.\n\n\n### Process - Continuous Delivery\n\nThe idea of automated deployment is important. Indeed, if you take automating the deployment process to its logical conclusion, you could push every build that passes the necessary automated tests into production. The practice of automatically deploying every successful build directly into production is generally known as Continuous Deployment.\n\nHowever, a pure Continuous Deployment approach is not always appropriate for everyone. For example, many users would not appreciate new versions falling into their laps several times a week, and prefer a more predictable (and transparent) release cycle. Commercial and marketing considerations might also play a role in when a new release should actually be deployed. The notion of Continuous Delivery is a slight variation on the idea of Continuous Deployment that takes into account these considerations.\n\n[Spinnaker](http://www.spinnaker.io/) is an open source, multi-cloud continuous delivery platform for releasing software changes with high velocity and confidence.\n\n[Jenkins 2](https://jenkins.io/2.0/) pipelines are pretty neat to. I don''t think Spinnaker will every fully replace Jenkins and the million things it does. Spinnaker goal is to just make the ''deploy to cloud'' step simpler and more extensible.\n\n[CircleCI''s](https://circleci.com) continuous integration and delivery platform helps software teams rapidly release code with confidence by automating the build, test, and deploy process. CircleCI offers a modern software development platform that lets teams ramp quickly, scale easily, and build confidently every day. CircleCI offers a total of four free linux containers ($2400 annual value) for open-source projects.\n\n[Travis CI](https://travis-ci.org/) - Test and Deploy with Confidence. Testing your open source project is 10000% free with Travis CI.\n\n### The lab\n\nI have constucted a [lab](http://ivans-innovation-lab.github.io/). It is hosted on [Github](https://github.com/ivans-innovation-lab).\n\nThe intention of this lab is to build information system of fictitious company.\n\nYou will learn how we:\n\n- made decisions to use one pattern against the other,\n- changed architecture, organization (culture) and process over time to respond to new requirements,\n- made a foundation for successful digitalization.\n\nThe ultimate goal is to deliver better software faster. Feel free to join. Let''s learn together!\n",
                "accelerating-the-digitization",
                Boolean.TRUE,
                Boolean.FALSE,
                future.getTime(),
                BlogPostCategory.ENGINEERING,
                CURRENT_USER
        );

        commandGateway.sendAndWait(command);

        future.add(Calendar.DAY_OF_YEAR, 10);
        command = new CreateBlogPostCommand(
                auditEntry,
                "Being a software architect",
                "Being a software architect involves much more than just knowing technology. Aside from being an excellent developer, you also have to be a leader.\\n\\n## Expectations\\nIt is expected of you to:\\n\\n- Analyze technology, industry and market trends and keep current with those latest trends.\\n- Analyze current technology environment and recommend solutions for improvement.\\n- Ensure compliance with the architecture\\n- Have exposure to multiple and diverse technologies, platforms and environments\\n- Possess exceptional interpersonal skills, including teamwork, facilitation and negotiation\\n- Define architecture and design principles to guide technology decisions for the enterprise\\n- Understand the political climate of the enterprise and be able to navigate the politics.\\n\\n## Aspects\\nMain aspects of this role are:\\n\\n- leadership and communication\\n- technical knowledge\\n- business domain knowledge\\n- methodology and strategy\\n\\n### Leadership and Communication\\n\\n#### Three C\\u2019s:\\n\\n- communication (effectively communicate ideas, concepts, issues and solutions to stakeholders)\\n- collaboration (get stakeholders involved in the architecture process and solicit ideas and feedback early and often)\\n- clarity (articulate the architecture solution in clear and concise terms as appropriate to each stakeholder)\\n\\n#### Translation skills\\n\\n- \\u201cBusiness is constantly changing to meet demands of the marketplace\\u201d -&gt; Agility, Maintainability\\n- \\u201cDue the new regulatory requirements, it is imperative that we complete end-of- day processing in time\\u201d -&gt; Performance, Scalability\\n- \\u201cWe need faster time to market to remain competitive\\u201d -&gt; Agility, Maintainability\\n- \\u201cOur plan is to engage heavily in mergers and acquisitions in the next three years \\u201c-&gt; Flexibility, Scalability, Integrations.\\n- \\u201cWe have a very tight timeframe and budget for this project\\u201d -&gt; feasibility\\n\\n### Technical Knowledge\\n\\n#### Triangle of knowledge\\n\\n- at the top: stuff you know (technical depth)\\n- second level: stuff you know you don\\u2019t know (technical breadth)\\n- third level: stuff you do not know you don\\u2019t know\\n\\nFocus on the second level.\\n\\n#### Multi-platform knowledge\\n\\n- golden hammer antipattern - one platform to rule them all\\n- overview multiple platforms to solve the problem\\n\\n### Business domain knowledge\\n\\nIt is important that an architect understand the business.\\n\\n- communicate better with the business\\n- better understand business goals, issues and trends\\n- gain trust by speaking the business language\\n- design the system to better handle the future changes\\n- better determine the correct architecture pattern\\n\\n### Methodology and strategy\\n\\nOnce you know where to go, how do you get there?\\n\\nBe aware of many different methodologies. You can influence on the business to choose right methodology\\n\\n#### Sample scenarios\\n\\n**Scanario 1.** Do not choose Waterfall Model\\n\\n- incomplete requirements\\n- you expect a lot of change\\n- tight budget and timeframe\\n\\n**Scenario 2.** Do not choose Scrum or agile\\n\\n- large and complex project\\n- multiple remote teams\\n- integrated maintenance\\n\\n**Scenario 3.** Hybrid\\n\\n- try to create a hybrid to strike the right balance\\n\\n**Regardless of what you do, as an architect you have to make it work!**'), STRINGDECODE('Being a software architect involves much more than just knowing technology. Aside from being an excellent developer, you also have to be a leader.\\n\\n## Expectations\\nIt is expected of you to:\\n\\n- Analyze technology, industry and market trends and keep current with those latest trends.\\n- Analyze current technology environment and recommend solutions for improvement.\\n- Ensure compliance with the architecture\\n- Have exposure to multiple and diverse technologies, platforms and environments\\n- Possess exceptional interpersonal skills, including teamwork, facilitation and negotiation\\n- Define architecture and design principles to guide technology decisions for the enterprise\\n- Understand the political climate of the enterprise and be able to navigate the politics.\\n\\n## Aspects\\nMain aspects of this role are:\\n\\n- leadership and communication\\n- technical knowledge\\n- business domain knowledge\\n- methodology and strategy\\n\\n### Leadership and Communication\\n\\n#### Three C\\u2019s:\\n\\n- communication (effectively communicate ideas, concepts, issues and solutions to stakeholders)\\n- collaboration (get stakeholders involved in the architecture process and solicit ideas and feedback early and often)\\n- clarity (articulate the architecture solution in clear and concise terms as appropriate to each stakeholder)\\n\\n#### Translation skills\\n\\n- \\u201cBusiness is constantly changing to meet demands of the marketplace\\u201d -&gt; Agility, Maintainability\\n- \\u201cDue the new regulatory requirements, it is imperative that we complete end-of- day processing in time\\u201d -&gt; Performance, Scalability\\n- \\u201cWe need faster time to market to remain competitive\\u201d -&gt; Agility, Maintainability\\n- \\u201cOur plan is to engage heavily in mergers and acquisitions in the next three years \\u201c-&gt; Flexibility, Scalability, Integrations.\\n- \\u201cWe have a very tight timeframe and budget for this project\\u201d -&gt; feasibility\\n\\n### Technical Knowledge\\n\\n#### Triangle of knowledge\\n\\n- at the top: stuff you know (technical depth)\\n- second level: stuff you know you don\\u2019t know (technical breadth)\\n- third level: stuff you do not know you don\\u2019t know\\n\\nFocus on the second level.\\n\\n#### Multi-platform knowledge\\n\\n- golden hammer antipattern - one platform to rule them all\\n- overview multiple platforms to solve the problem\\n\\n### Business domain knowledge\\n\\nIt is important that an architect understand the business.\\n\\n- communicate better with the business\\n- better understand business goals, issues and trends\\n- gain trust by speaking the business language\\n- design the system to better handle the future changes\\n- better determine the correct architecture pattern\\n\\n### Methodology and strategy\\n\\nOnce you know where to go, how do you get there?\\n\\nBe aware of many different methodologies. You can influence on the business to choose right methodology\\n\\n#### Sample scenarios\\n\\n**Scanario 1.** Do not choose Waterfall Model\\n\\n- incomplete requirements\\n- you expect a lot of change\\n- tight budget and timeframe\\n\\n**Scenario 2.** Do not choose Scrum or agile\\n\\n- large and complex project\\n- multiple remote teams\\n- integrated maintenance\\n\\n**Scenario 3.** Hybrid\\n\\n- try to create a hybrid to strike the right balance\\n\\n**Regardless of what you do, as an architect you have to make it work!**",
                "being-a-software-architect",
                Boolean.TRUE,
                Boolean.TRUE,
                future.getTime(),
                BlogPostCategory.NEWS_AND_EVENTS,
                CURRENT_USER
        );
        commandGateway.sendAndWait(command);

        future.add(Calendar.DAY_OF_YEAR, 5);
        command = new CreateBlogPostCommand(
                auditEntry,
                "Continuous delivery in the cloud",
                "The idea of automated deployment is important. Indeed, if you take automating the deployment process to its logical conclusion, you could push every build that passes the necessary automated tests into production. The practice of automatically deploying every successful build directly into production is generally known as Continuous Deployment.\\n\\nHowever, a pure Continuous Deployment approach is not always appropriate for everyone. For example, many users would not appreciate new versions falling into their laps several times a week, and prefer a more predictable \\\\(and transparent\\\\) release cycle. Commercial and marketing considerations might also play a role in when a new release should actually be deployed. The notion of Continuous Delivery is a variation on the idea of Continuous Deployment that takes into account these considerations.\\n\\nThe key pattern introduced in continuous delivery is the _deployment pipeline._\\n\\nIn the deployment pipeline pattern, every change in version control triggers a process \\\\(usually in a [CI](https://continuousdelivery.com/foundations/continuous-integration/) server\\\\) which creates deployable packages and runs automated unit tests and other validations such as static code analysis. This first step is optimized so that it takes only a few minutes to run. If this initial commit stage fails, the problem must be fixed immediately\\u2014nobody should check in more work on a broken commit stage. Every passing commit stage triggers the next step in the pipeline, which might consist of a more comprehensive set of automated tests. Versions of the software that pass all the automated tests can then be deployed on demand to further stages such as exploratory testing, performance testing, staging, and production, as shown below.\\n\\n## Deployment pipeline\\n\\n**This is a real-life, open-source, java, maven, spring-boot [application](https://github.com/ivans-innovation-lab/my-company-monolith)** with monolithic architectural style. Domain Driven Design is applied through Event Sourcing and CQRS. How Event Sourcing enables deployment flexibility - the monolithic application can be migrated and deployed as a microservices. You can find more information about the structure of application/s [here](http://ivans-innovation-lab.github.io/projects).\\n\\nThe infrastructure and tools needed for the pipeline are:\\n\\n* [Artifactory](https://www.jfrog.com/artifactory/) as Maven repository on AWS\\n  * [http://maven.idugalic.pro](http://maven.idugalic.pro)\\n* [CircleCI](https://circleci.com/) as continuous integration and delivery platform\\n* [PWS](http://run.pivotal.io/) - an instance of the Cloud Foundry platform-as-a-service operated by Pivotal Software, Inc.\\n\\n\\nThis \\\"Pipeline as Code\\\" is written to a [.circleci/config.yml](https://github.com/ivans-innovation-lab/my-company-monolith/blob/master/.circleci/config.yml) and checked into a project\\u2019s source control repository.\\n\\n\\nThe following example shows a [pipeline](https://circleci.com/gh/ivans-innovation-lab/workflows/my-company-monolith) with seven sequential jobs. The jobs run according to configured requirements, each job waiting to start until the required job finishes successfully. This pipeline is configured to wait for manual approval of a job ''approve-production'' before continuing by using the `type: approval` key. The `type: approval` key is a special job that is only added under your `workflow` key\\n\\n![](https://github.com/idugalic/idugalic.github.io/raw/master/images/Screen%20Shot%202017-09-09%20at%201.13.34%20PM.png)\\n\\n### Staging\\n\\nEvery push to **master** branch \\\\(every time you merge a feature branch\\\\) will trigger the pipeline and the application will be deployed to PWS on ''**Stage**'' space:![](https://docs.lab.idugalic.pro/assets/Screen%20Shot%202017-06-21%20at%201.28.42%20PM.png)Additionally, a current production artifact will be deployed on Stage by ''staging-prod'' job for DB schema backward compatibility testing \\\\(we will test old application against new DB schema\\\\). This will enable Blue-Green deployment with roll-back option, as shown below under Blue-Green Deployment section.\\n\\n### Production\\n\\nOnce you are ready to deploy to **production** you should manually approve deployment to production in you CircleCI workflow/pipeline. This will trigger next job \\\\(production\\\\) and the application will be deployed (with zero-downtime) to PWS on ''**Prod**'' space:![](https://docs.lab.idugalic.pro/assets/Screen%20Shot%202017-06-21%20at%201.28.58%20PM.png)You can consider removing manual step (approve) and practice Continuous Deployment instead of Continuous Delivery ;)\\n\\n### Requirements\\n\\nFor the pipeline to work you have to create two spaces \\\\(environments\\\\) on PWS:\\n\\n* Stage\\n* Prod\\n\\nOn each space you have to create instance of ClearDB MySQL service \\\\(database\\\\):\\n\\n```\\ncf api https://api.run.pivotal.io\\ncf auth EMAIL PASSWORD\\ncf target -o idugalic -s Stage\\ncf create-service cleardb spark mysql\\ncf t -s Prod\\ncf create-service cleardb spark mysql\\n```\\n\\nNOTE: Instructions to install CloudFoundry CLI \\\\(cf\\\\): [https://docs.cloudfoundry.org/cf-cli/install-go-cli.html](https://docs.cloudfoundry.org/cf-cli/install-go-cli.html)\\n\\n### Metrics\\n\\nPCF Metrics helps you understand and troubleshoot the health and performance of your apps by displaying the following:\\n\\n* [Container Metrics](http://docs.run.pivotal.io/metrics/using.html#container)\\n   A graph of CPU, memory, and disk usage percentages\\n* [Network Metrics](http://docs.run.pivotal.io/metrics/using.html#network)\\n   A graph of requests, HTTP errors, and response times\\n* [App Events](http://docs.run.pivotal.io/metrics/using.html#events)\\n   A graph of update, start, stop, crash, SSH, and staging failure events\\n* [Logs](http://docs.run.pivotal.io/metrics/using.html#logs)\\n   A list of app logs that you can search, filter, and download\\n* [Trace Explorer](http://docs.run.pivotal.io/metrics/using.html#trace)\\n   A graph that traces a request as it flows through your apps and their endpoints, along with the corresponding logs\\n\\n![](https://docs.lab.idugalic.pro/assets/Screen%20Shot%202017-06-16%20at%2011.45.31%20AM.png)\\n\\n### Autoscaler\\n\\n[App Autoscaler](https://docs.run.pivotal.io/appsman-services/autoscaler/using-autoscaler.html) is a marketplace service that ensures app performance and helps control the cost of running apps.\\n\\nTo balance app performance and cost, Space Developers and Space Managers can use App Autoscaler to do the following:\\n\\n* Configure rules that adjust instance counts based on metrics thresholds such as CPU Usage\\n* Modify the maximum and minimum number of instances for an app, either manually or following a schedule\\n\\n### Spring Boot Actuator\\n\\nAdding Actuator to your Spring Boot application deployed on Pivotal Cloud Foundry gets you the following production-ready features:\\n\\n* Health Check column & expanded information in Instances section\\n* git commit id indicator, navigable to your git repo\\n* Summary git info under Settings tab \\\\(also navigable to repo\\\\)\\n* Runtime adjustment of logging levels, exposed via Actuator endpoints\\n* Heap Dump\\\\*\\n* View Trace\\\\*\\n* View Threads, dump/download for further analysis\\\\*\\n\\n### Blue-Green Deployment\\n\\n[Blue-green deployment](https://docs.run.pivotal.io/devguide/deploy-apps/blue-green.html) is a release technique that reduces downtime and risk by running two identical production environments called Blue and Green.\\n\\nAt any time, only one of the environments is live, with the live environment serving all production traffic. For this example, Blue is currently live and Green is idle.\\n\\nAs you prepare a new release of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.\\n\\nThis technique can eliminate downtime due to application deployment. In addition, blue-green deployment reduces risk: if something unexpected happens with your new release on Green, you can immediately roll back to the last version by switching back to Blue.\\n\\nBlue-green deployment is implemented by ''production'' job in the [workflow](https://github.com/ivans-innovation-lab/my-company-monolith/blob/master/.circleci/config.yml).\\n\\nDoing Blue-green deployment with database schema changing is not easy. We have to [change the schema](https://martinfowler.com/books/refactoringDatabases.html) in such a way that Blue-green deployment and roll-back to the previous version are possible, usually by making DB changes backward compatible (this makes DB schema backward compatibility testing an important step). For this we need schema versioning first \\\\([Flyway](http://flywaydb.org/)\\\\). I was inspired with this [blog post](https://spring.io/blog/2016/05/31/zero-downtime-deployment-with-a-database). There you can find more details.\\n\\nYou can design your database in the 6th normal form an make you scheme more adaptable and your process more agile. I was inspired with this [blog post](https://blog.codecentric.de/en/2017/07/agile-database-design-using-anchor-modeling/ ).\\n'), STRINGDECODE('The idea of automated deployment is important. Indeed, if you take automating the deployment process to its logical conclusion, you could push every build that passes the necessary automated tests into production. The practice of automatically deploying every successful build directly into production is generally known as Continuous Deployment.\\n\\nHowever, a pure Continuous Deployment approach is not always appropriate for everyone. For example, many users would not appreciate new versions falling into their laps several times a week, and prefer a more predictable \\\\(and transparent\\\\) release cycle. Commercial and marketing considerations might also play a role in when a new release should actually be deployed. The notion of Continuous Delivery is a variation on the idea of Continuous Deployment that takes into account these considerations.\\n\\nThe key pattern introduced in continuous delivery is the _deployment pipeline._\\n\\nIn the deployment pipeline pattern, every change in version control triggers a process \\\\(usually in a [CI](https://continuousdelivery.com/foundations/continuous-integration/) server\\\\) which creates deployable packages and runs automated unit tests and other validations such as static code analysis. This first step is optimized so that it takes only a few minutes to run. If this initial commit stage fails, the problem must be fixed immediately\\u2014nobody should check in more work on a broken commit stage. Every passing commit stage triggers the next step in the pipeline, which might consist of a more comprehensive set of automated tests. Versions of the software that pass all the automated tests can then be deployed on demand to further stages such as exploratory testing, performance testing, staging, and production, as shown below.\\n\\n## Deployment pipeline\\n\\n**This is a real-life, open-source, java, maven, spring-boot [application](https://github.com/ivans-innovation-lab/my-company-monolith)** with monolithic architectural style. Domain Driven Design is applied through Event Sourcing and CQRS. How Event Sourcing enables deployment flexibility - the monolithic application can be migrated and deployed as a microservices. You can find more information about the structure of application/s [here](http://ivans-innovation-lab.github.io/projects).\\n\\nThe infrastructure and tools needed for the pipeline are:\\n\\n* [Artifactory](https://www.jfrog.com/artifactory/) as Maven repository on AWS\\n  * [http://maven.idugalic.pro](http://maven.idugalic.pro)\\n* [CircleCI](https://circleci.com/) as continuous integration and delivery platform\\n* [PWS](http://run.pivotal.io/) - an instance of the Cloud Foundry platform-as-a-service operated by Pivotal Software, Inc.\\n\\n\\nThis \\\"Pipeline as Code\\\" is written to a [.circleci/config.yml](https://github.com/ivans-innovation-lab/my-company-monolith/blob/master/.circleci/config.yml) and checked into a project\\u2019s source control repository.\\n\\n\\nThe following example shows a [pipeline](https://circleci.com/gh/ivans-innovation-lab/workflows/my-company-monolith) with seven sequential jobs. The jobs run according to configured requirements, each job waiting to start until the required job finishes successfully. This pipeline is configured to wait for manual approval of a job ''approve-production'' before continuing by using the `type: approval` key. The `type: approval` key is a special job that is only added under your `workflow` key\\n\\n![](https://github.com/idugalic/idugalic.github.io/raw/master/images/Screen%20Shot%202017-09-09%20at%201.13.34%20PM.png)\\n\\n### Staging\\n\\nEvery push to **master** branch \\\\(every time you merge a feature branch\\\\) will trigger the pipeline and the application will be deployed to PWS on ''**Stage**'' space:![](https://docs.lab.idugalic.pro/assets/Screen%20Shot%202017-06-21%20at%201.28.42%20PM.png)Additionally, a current production artifact will be deployed on Stage by ''staging-prod'' job for DB schema backward compatibility testing \\\\(we will test old application against new DB schema\\\\). This will enable Blue-Green deployment with roll-back option, as shown below under Blue-Green Deployment section.\\n\\n### Production\\n\\nOnce you are ready to deploy to **production** you should manually approve deployment to production in you CircleCI workflow/pipeline. This will trigger next job \\\\(production\\\\) and the application will be deployed (with zero-downtime) to PWS on ''**Prod**'' space:![](https://docs.lab.idugalic.pro/assets/Screen%20Shot%202017-06-21%20at%201.28.58%20PM.png)You can consider removing manual step (approve) and practice Continuous Deployment instead of Continuous Delivery ;)\\n\\n### Requirements\\n\\nFor the pipeline to work you have to create two spaces \\\\(environments\\\\) on PWS:\\n\\n* Stage\\n* Prod\\n\\nOn each space you have to create instance of ClearDB MySQL service \\\\(database\\\\):\\n\\n```\\ncf api https://api.run.pivotal.io\\ncf auth EMAIL PASSWORD\\ncf target -o idugalic -s Stage\\ncf create-service cleardb spark mysql\\ncf t -s Prod\\ncf create-service cleardb spark mysql\\n```\\n\\nNOTE: Instructions to install CloudFoundry CLI \\\\(cf\\\\): [https://docs.cloudfoundry.org/cf-cli/install-go-cli.html](https://docs.cloudfoundry.org/cf-cli/install-go-cli.html)\\n\\n### Metrics\\n\\nPCF Metrics helps you understand and troubleshoot the health and performance of your apps by displaying the following:\\n\\n* [Container Metrics](http://docs.run.pivotal.io/metrics/using.html#container)\\n   A graph of CPU, memory, and disk usage percentages\\n* [Network Metrics](http://docs.run.pivotal.io/metrics/using.html#network)\\n   A graph of requests, HTTP errors, and response times\\n* [App Events](http://docs.run.pivotal.io/metrics/using.html#events)\\n   A graph of update, start, stop, crash, SSH, and staging failure events\\n* [Logs](http://docs.run.pivotal.io/metrics/using.html#logs)\\n   A list of app logs that you can search, filter, and download\\n* [Trace Explorer](http://docs.run.pivotal.io/metrics/using.html#trace)\\n   A graph that traces a request as it flows through your apps and their endpoints, along with the corresponding logs\\n\\n![](https://docs.lab.idugalic.pro/assets/Screen%20Shot%202017-06-16%20at%2011.45.31%20AM.png)\\n\\n### Autoscaler\\n\\n[App Autoscaler](https://docs.run.pivotal.io/appsman-services/autoscaler/using-autoscaler.html) is a marketplace service that ensures app performance and helps control the cost of running apps.\\n\\nTo balance app performance and cost, Space Developers and Space Managers can use App Autoscaler to do the following:\\n\\n* Configure rules that adjust instance counts based on metrics thresholds such as CPU Usage\\n* Modify the maximum and minimum number of instances for an app, either manually or following a schedule\\n\\n### Spring Boot Actuator\\n\\nAdding Actuator to your Spring Boot application deployed on Pivotal Cloud Foundry gets you the following production-ready features:\\n\\n* Health Check column & expanded information in Instances section\\n* git commit id indicator, navigable to your git repo\\n* Summary git info under Settings tab \\\\(also navigable to repo\\\\)\\n* Runtime adjustment of logging levels, exposed via Actuator endpoints\\n* Heap Dump\\\\*\\n* View Trace\\\\*\\n* View Threads, dump/download for further analysis\\\\*\\n\\n### Blue-Green Deployment\\n\\n[Blue-green deployment](https://docs.run.pivotal.io/devguide/deploy-apps/blue-green.html) is a release technique that reduces downtime and risk by running two identical production environments called Blue and Green.\\n\\nAt any time, only one of the environments is live, with the live environment serving all production traffic. For this example, Blue is currently live and Green is idle.\\n\\nAs you prepare a new release of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.\\n\\nThis technique can eliminate downtime due to application deployment. In addition, blue-green deployment reduces risk: if something unexpected happens with your new release on Green, you can immediately roll back to the last version by switching back to Blue.\\n\\nBlue-green deployment is implemented by ''production'' job in the [workflow](https://github.com/ivans-innovation-lab/my-company-monolith/blob/master/.circleci/config.yml).\\n\\nDoing Blue-green deployment with database schema changing is not easy. We have to [change the schema](https://martinfowler.com/books/refactoringDatabases.html) in such a way that Blue-green deployment and roll-back to the previous version are possible, usually by making DB changes backward compatible (this makes DB schema backward compatibility testing an important step). For this we need schema versioning first \\\\([Flyway](http://flywaydb.org/)\\\\). I was inspired with this [blog post](https://spring.io/blog/2016/05/31/zero-downtime-deployment-with-a-database). There you can find more details.\\n\\nYou can design your database in the 6th normal form an make you scheme more adaptable and your process more agile. I was inspired with this [blog post](https://blog.codecentric.de/en/2017/07/agile-database-design-using-anchor-modeling/ ).\\n",
                "continuous-delivery-in-the-cloud",
                Boolean.FALSE,
                Boolean.TRUE,
                future.getTime(),
                BlogPostCategory.ENGINEERING,
                CURRENT_USER
        );
        commandGateway.sendAndWait(command);
    }
}

